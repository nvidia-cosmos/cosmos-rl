redis = "12800"
mode = "colocated"

[policy]
model_name_or_path = "nvidia/Cosmos-Predict2.5-2B"
model_revision = "diffusers/base/post-trained"
is_diffusers = true
model_gradient_checkpointing = true

[policy.lora]
lora_names = ["default", "old"]
r = 32
lora_alpha = 64
init_lora_weights = "gaussian"
target_modules = [ # Set both attention and cross-attention modules
    "to_k",
    "to_out.0",
    "to_q",
    "to_v",
    "ff.net.0.proj",
    "ff.net.2",
]

[policy.diffusers]
dtype = "float32"
is_video = true
offload = false
max_prompt_length = 512
inference_size = [512, 512]
timestep_fraction = 0.99
weight_copy_decay_type = 1
train_frames = 93

[policy.diffusers.sample]
num_steps = 10
eval_num_steps = 40
guidance_scale = 1.0
noise_level = 0.7
solver = "dpm2"
deterministic_sampling = true

[rollout]
backend = "diffusion_nft_rollout"
n_generation = 12

[logging]
logger = ['console', 'wandb']
project_name = "cosmos_rl"
experiment_name = "None"

[train]
non_text = true
resume = false
train_batch_per_replica = 32  # 4*8
epoch = 10
output_dir = "./outputs/cosmos-predict2-5_2b-medium_720_nft"
epsilon = 1e-8
optm_name = "AdamW"
optm_lr = 3e-4
optm_impl = "foreach"
optm_weight_decay = 1e-4
optm_betas = [ 0.9, 0.999,]
optm_grad_norm_clip = 1.0
ema_enable = true
ema_decay = 0.9
ema_update_step_interval = 1
async_tp_enabled = false
compile = false

[train.train_policy]
type = "grpo"
trainer_type = "diffusion_nft"
use_remote_reward = true
uncentralized_training = true
dataset.name = "pickscore"
dataset.split = "train"
kl_beta = 1.0
advantage_high = 5.0
advantage_low = -5.0

[train.train_policy.remote_reward]
score_key = "overall_reward"
scale = 1.0

[train.train_policy.remote_reward.reward_fn]
dance_grpo = 1.0

[train.ckpt]
enable_checkpoint = false
save_freq = 5
save_mode = "async"

[validation]
dataset.name = "pickscore"
dataset.split = "test"

[rollout.parallelism]
n_init_replicas = 1
tp_size = 1
dp_shard_size = 8
pp_size = 1

[policy.parallelism]
n_init_replicas = 1
tp_size = 1
cp_size = 1
dp_shard_size = 8
pp_size = 1
dp_replicate_size = 1
