redis = "12800"

[train]
resume = false
max_num_steps = 15000
epoch = 9999999
output_dir = "./outputs/pi05/behavior_sft"
optm_name = "AdamW"
optm_lr = 1e-6
optm_impl = "fused"
optm_weight_decay = 1e-10
optm_betas = [0.9, 0.95]
optm_warmup_steps = 1000
optm_grad_norm_clip = 1.0
optm_decay_type = "cosine"
optm_decay_ratio = 1.0
epsilon = 1e-8
compile = true
param_dtype = "bfloat16"
fsdp_reduce_dtype = "float32"
fsdp_offload = false
fsdp_reshard_after_forward = "default"
train_batch_per_replica = 64
sync_weight_interval = 1

[train.ckpt]
enable_checkpoint = true
save_freq = 5000
save_mode = "async"

[policy]
model_name_or_path = "/workspace/comet_weights_pytorch_2/pi05-b1kpt50-cs32"
model_gradient_checkpointing = true

[policy.parallelism]
n_init_replicas = 1
tp_size = 1
cp_size = 1
dp_shard_size = 1
pp_size = 1
dp_replicate_size = 8

[logging]
logger = ["console", "wandb"]
project_name = "sft-debug"
experiment_name = "cosmos-rl-test"

[train.train_policy]
type = "sft"
trainer_type = "pi_sft"
mini_batch = 64
dataloader_num_workers = 8

[train.train_policy.dataset]
name = "behavior-1k/2025-challenge-demos"
local_dir = "/workspace/2025-challenge-demos"

[validation]
enable = false

[custom]
action_dim = 32
action_horizon = 32
action_sequence_keys = ["action"]
image_size = [224, 224]
max_token_len = 200
num_steps = 10
action_chunk = 32
action_env_dim = 23
train_expert_only = false
discrete_state_input = true
tasks = ["setting_the_fire"]
modalities = ["rgb"]
model_type = "PI05"
prompt_from_task = true
skip_norm_stats = false
norm_stats="/workspace/comet_weights_pytorch_2/pi05-b1kpt50-cs32/assets/behavior-1k/2025-challenge-demos/norm_stats.json" # default use json from resumed weights
episodes_index = [0, 200]
add_dataset_name = "delinqu/comet-1.5k"
add_dataset_local_dir = "/workspace/comet-1.5k"
add_data_multiplier = 2