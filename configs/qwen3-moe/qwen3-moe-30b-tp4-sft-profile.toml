redis = "12808"

[train]
resume = false
epoch = 1
output_dir = "./outputs/qwen3-moe-30b-tp8-sft"
epsilon = 1e-6
optm_name = "AdamW"
optm_lr = 1e-6
optm_impl = "foreach"
optm_weight_decay = 0.01
optm_betas = [0.9, 0.999]
optm_warmup_steps = 20
optm_grad_norm_clip = 1.0
async_tp_enabled = false
compile = false
param_dtype = "bfloat16"
fsdp_reduce_dtype = "float32"
fsdp_offload = false
fsdp_reshard_after_forward = "default"
train_batch_per_replica = 32
sync_weight_interval = 1

[policy]
model_name_or_path = "Qwen/Qwen3-30B-A3B"
model_max_length = 1024 
model_gradient_checkpointing = true

[logging]
logger = ['console', 'wandb']
project_name = "cosmos_rl"
experiment_name = "None"

[train.train_policy]
type = "sft"
dataset.name = "LNTANOooo/sharegpt52k"
dataset.subset = ""
dataset.split = "train"
conversation_column_name = "conversation"
mini_batch = 2

[train.ckpt]
enable_checkpoint = true
save_freq = 2000
save_mode = "async"

[policy.parallelism]
n_init_replicas = 1
tp_size = 4
cp_size = 1
dp_shard_size = 1
pp_size = 1
dp_replicate_size = 1

[profiler]
enable_profiler = true
enable_nsys = false

[profiler.sub_profiler_config]
active_steps = 1
rank_filter = [0,1,2,3,4,5,6,7]
record_shape = true
profile_memory = false
with_stack = true
with_modules = true
